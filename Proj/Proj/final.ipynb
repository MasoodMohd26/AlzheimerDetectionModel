{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "\n",
    "f = open(\"C://Users//vijva//Documents//PB//GSE84422-GPL570_series_matrix.txt\")\n",
    "\n",
    "r = f.readlines()\n",
    "\n",
    "for i in range(14):\n",
    "    if(i!=13):\n",
    "        l = r[i].split()\n",
    "        del l[0]\n",
    "        r[i] = l\n",
    "    else:\n",
    "        l = r[i].split()\n",
    "        ll = len(l[0])\n",
    "        r[i] = r[i][ll+1:].split(\"\\t\")\n",
    "        #print(len(r[i]))\n",
    "\n",
    "\n",
    "        \n",
    "#print(r[13])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c = r[1].count('\"subject')\n",
    "\n",
    "for i in range(c):\n",
    "    r[1].remove('\"subject')\n",
    "\n",
    "\n",
    "c = r[1].count('id:')\n",
    "\n",
    "for i in range(c):\n",
    "    r[1].remove('id:')\n",
    "    \n",
    "for i in range(2,8):\n",
    "    ch = r[i][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[i].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[i].remove(ch)\n",
    "        \n",
    "for i in range(2):\n",
    "    ch = r[7][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[7].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[7].remove(ch)\n",
    "        \n",
    "for i in range(2):\n",
    "    ch = r[5][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[5].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[5].remove(ch)\n",
    "        \n",
    "for i in range(4):\n",
    "    ch = r[8][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[8].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[8].remove(ch)\n",
    "        \n",
    "for i in range(2):\n",
    "    ch = r[9][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[9].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[9].remove(ch)\n",
    "        \n",
    "for i in range(4):\n",
    "    ch = r[10][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[10].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[10].remove(ch)\n",
    "        \n",
    "for i in range(5):\n",
    "    ch = r[11][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[11].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[11].remove(ch)\n",
    "        \n",
    "for i in range(9):\n",
    "    ch = r[12][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    c = r[12].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[12].remove(ch)\n",
    "        \n",
    "'''for i in range(2):\n",
    "    ch = r[13][0]\n",
    "    #print(ch)\n",
    "    \n",
    "    \n",
    "    c = r[13].count(ch)\n",
    "    \n",
    "    for j in range(c):\n",
    "        r[13].remove(ch)'''\n",
    "\n",
    "\n",
    "for i in range(len(r[13])):\n",
    "    st = str(r[13][i][14:])\n",
    "    #print(\"st: \",st)\n",
    "    lst = st.split()\n",
    "    s = \"\".join(lst)\n",
    "    #print(\"s: \",s)\n",
    "    r[13][i] = s\n",
    "        \n",
    "\n",
    "\n",
    "for j in range(r[11].count('in')):\n",
    "    r[11].remove('in')\n",
    "    \n",
    "for j in range(r[11].count('multiple')):\n",
    "    r[11].remove('multiple')\n",
    "\n",
    "for j in range(r[11].count('brain')):\n",
    "    r[11].remove('brain')\n",
    "\n",
    "for j in range(r[11].count('regions:')):\n",
    "    r[11].remove('regions:')\n",
    "    \n",
    "for j in range(r[9].count('AD\"')):\n",
    "    r[9].remove('AD\"')\n",
    "    \n",
    "    \n",
    "'''for j in range(r[13].count('Accumbens\"')):\n",
    "    r[13].remove('Accumbens\"')'''\n",
    "    \n",
    "'''for i in range(14):\n",
    "    print(r[i])  '''\n",
    "\n",
    "#print(r[6])\n",
    "\n",
    "#for i in r:\n",
    " #   print(len(i))\n",
    "        \n",
    "d = {\"id_ref\":r[0],\"subject_id\":r[1],\"age\":r[2],\"sex\":r[3],\"race\":r[4],\"postmortem_interval\":r[5],\"ph\":r[6],\"rating\":r[7],\"bnt\":r[8],\"cat\":r[9],\"anpd\":r[10],\"crssum\":r[11],\"ntdsum\":r[12],\"region\":r[13]}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"570(1).csv\")\n",
    "f = open(\"C://Users//vijva//Documents//PB//GSE84422-GPL570_series_matrix.txt\")\n",
    "r = f.readlines()\n",
    "d = {}\n",
    "\n",
    "for i in range(14,len(r)-1):\n",
    "    c = r[i].split()[0]\n",
    "    #print(c)\n",
    "    d[c] = r[i].split()[1:]\n",
    "    \n",
    "\n",
    "    \n",
    "df2 = pd.DataFrame(d)\n",
    "\n",
    "df2.to_csv(\"570(2).csv\")\n",
    "\n",
    "df = pd.read_csv(\"C://Users//vijva//Documents//PB//Proj//96(1).csv\")\n",
    "df.drop('Unnamed: 0',axis = 1,inplace=True)\n",
    "df.set_index('id_ref',inplace=True)\n",
    "print(len(df.index.unique()))\n",
    "df2 = pd.read_csv(\"C://Users//vijva//Documents//PB//Proj//96(2).csv\")\n",
    "df2.drop('Unnamed: 0',axis = 1,inplace=True)\n",
    "df2.index.name = 'id_ref'\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "l = df.index\n",
    "ll = [i for i in l]\n",
    "\n",
    "df2.index = ll\n",
    "df2.index.name = 'id_ref'\n",
    "df2.head()\n",
    "df3 = pd.merge(df,df2,on = 'id_ref')\n",
    "df3.shape\n",
    "df3.head()\n",
    "\n",
    "df3.cat.value_counts()\n",
    "\n",
    "l = {'definite':3,'Possible':1,'Normal':0,'Probable':2}\n",
    "\n",
    "df3.cat = [l[i] for i in df3.cat]\n",
    "df3.head()\n",
    "cm = df2.T\n",
    "cm.index.name = ''\n",
    "met = pd.DataFrame()\n",
    "met.index = cm.columns\n",
    "met.index.name = 'id_ref'\n",
    "\n",
    "met = pd.merge(met,df3['cat'],on = 'id_ref')\n",
    "met.head()\n",
    "\n",
    "\n",
    "cm.round(0)\n",
    "cm = cm.astype('int')\n",
    "cm.head()\n",
    "\n",
    "cm = cm.T\n",
    "print(cm.shape)\n",
    "met.shape\n",
    "met.rename({'cat':'condition'},axis = 1,inplace=True)\n",
    "\n",
    "met.head()\n",
    "\n",
    "\n",
    "inference = DefaultInference()\n",
    "data = DeseqDataSet(counts=cm,metadata=met,design_factors=\"condition\",\n",
    "    refit_cooks=True,\n",
    "    inference=inference)\n",
    "geo = pd.read_csv(r\"GSE84422.top.table (2).tsv\",sep='\\t')\n",
    "geo['rank'] = -(np.log10(geo['P.Value']))*geo['logFC']\n",
    "geo['logp'] = -(np.log(geo['P.Value']))\n",
    "geo.head()\n",
    "\n",
    "\n",
    "sns.scatterplot(x = 'logFC',y = 'logp',data=geo)\n",
    "plt.axhline(y=-np.log10(0.05), color='red', linestyle='--')\n",
    "plt.axvline(x=np.log10(1.5), color='red', linestyle='--')\n",
    "plt.axvline(x=-np.log10(1.5), color='red', linestyle='--')\n",
    "\n",
    "geo.sort_values(by = \"rank\",inplace=True,ascending=False)\n",
    "geo.head()\n",
    "findata = geo[['Gene.symbol','rank']]\n",
    "findata.head()\n",
    "import gseapy as gp\n",
    "\n",
    "gp.get_library_name()\n",
    "findata.dropna(how = 'any',inplace=True)\n",
    "#rnk = gp.prerank(rnk = findata,gene_sets='GO_Biological_Process_2023',seed = 43)\n",
    "rnk = gp.prerank(rnk = findata,gene_sets='GO_Biological_Process_2023',seed = 43)\n",
    "\n",
    "rnk.results\n",
    "output = []\n",
    "\n",
    "dict = rnk.results\n",
    "\n",
    "for i in dict:\n",
    "    if(dict[i]['pval']<0.05 and (dict[i]['es']>0.8 or dict[i]['es']<-0.8)):\n",
    "       output.append([i,dict[i]['es'],dict[i]['nes'],dict[i]['pval'],dict[i]['lead_genes']])\n",
    "    \n",
    "output\n",
    "genedf = pd.DataFrame(columns = ['Gene name','es','nes','pval','lead_genes'],data = output)\n",
    "genedf.head()\n",
    "\n",
    "ess = genedf['es']\n",
    "sns.histplot(x = ess)\n",
    "df3.drop(index=[row for row in df3.index if df3.loc[row,'cat'] in [2,1]],inplace=True)\n",
    "deg = []\n",
    "\n",
    "d = geo['ID'][300:]\n",
    "\n",
    "print(list(d))\n",
    "\n",
    "d = df3[[i for i in d if i in df3.columns]]\n",
    "fina = df3\n",
    "#fina.shape\n",
    "X = fina[df3.columns[13:]]\n",
    "X.head()\n",
    "y = df3['cat']\n",
    "y.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=41)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "logreg = LogisticRegression(solver='saga',random_state=41)\n",
    "rf = RandomForestClassifier(random_state=41,n_estimators=100,max_features=400)\n",
    "abc = AdaBoostClassifier(random_state=41)\n",
    "gbc = GradientBoostingClassifier(random_state=41,max_features=60)\n",
    "svc = SVC(random_state=41)\n",
    "\n",
    "models = [gnb,knn,logreg,rf,abc,svc]\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "d={}\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit_transform(X,y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=41)\n",
    "\n",
    "    \n",
    "    \n",
    "for i in models:\n",
    "    print(i,\": \",end = \" \")\n",
    "    i.fit(X_train,y_train)\n",
    "    preds = i.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy: \",accuracy_score(y_test,preds))\n",
    "    \n",
    "genelist = []\n",
    "\n",
    "for i in genedf['lead_genes']:\n",
    "    s = i.strip().split(\";\")\n",
    "    for j in s:\n",
    "        if(j not in genelist):\n",
    "            genelist.append(j)\n",
    "            \n",
    "    \n",
    "print(len(genelist))\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "for i,j in geo.iterrows():\n",
    "    mapping[j[6]] = j[0]\n",
    "    \n",
    "mapping\n",
    "geo.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "geo.rename({'P.Value':'p-value'},axis = 1,inplace=True)\n",
    "geo.rename({'logFC':'log2_fold_change'},axis = 1,inplace=True)\n",
    "geo['rank'] = -(np.log10(geo['p-value']))*geo['log2_fold_change']\n",
    "\n",
    "geo['logp'] = -(np.log(geo['p-value']))\n",
    "geo.head()\n",
    "\n",
    "fold_change_threshold, p_value_threshold = np.log10(2), 0.05\n",
    "\n",
    "# Identify differentially expressed genes\n",
    "upregulated = geo[(geo['log2_fold_change'] > fold_change_threshold) & (geo['p-value'] < p_value_threshold)]\n",
    "downregulated = geo[(geo['log2_fold_change'] < -fold_change_threshold) & (geo['p-value'] < p_value_threshold)]\n",
    "no_change = geo[abs(geo['log2_fold_change']) <= fold_change_threshold]\n",
    "\n",
    "# Create volcano plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot genes with significant upregulation\n",
    "plt.scatter(upregulated['log2_fold_change'], -np.log10(upregulated['p-value']), color='red', label='Upregulated (significant)', alpha=0.5)\n",
    "\n",
    "# Plot genes with significant downregulation\n",
    "plt.scatter(downregulated['log2_fold_change'], -np.log10(downregulated['p-value']), color='blue', label='Downregulated (significant)', alpha=0.5)\n",
    "\n",
    "# Plot genes with no significant change\n",
    "plt.scatter(no_change['log2_fold_change'], -np.log10(no_change['p-value']), color='gray', label='No change', alpha=0.5)\n",
    "\n",
    "# Plot genes with upregulation but not significant\n",
    "plt.scatter(geo[(geo['log2_fold_change'] > fold_change_threshold) & (geo['p-value'] >= p_value_threshold)]['log2_fold_change'],\n",
    "            -np.log10(geo[(geo['log2_fold_change'] > fold_change_threshold) & (geo['p-value'] >= p_value_threshold)]['p-value']),\n",
    "            color='salmon', label='Upregulated (not significant)', alpha=0.5)\n",
    "\n",
    "# Plot genes with downregulation but not significant\n",
    "plt.scatter(geo[(geo['log2_fold_change'] < -fold_change_threshold) & (geo['p-value'] >= p_value_threshold)]['log2_fold_change'],\n",
    "            -np.log10(geo[(geo['log2_fold_change'] < -fold_change_threshold) & (geo['p-value'] >= p_value_threshold)]['p-value']),\n",
    "            color='lightblue', label='Downregulated (not significant)', alpha=0.5)\n",
    "\n",
    "# sns.scatterplot(x = 'logFC',y = 'logp',data=geo)\n",
    "\n",
    "plt.axhline(y=-np.log10(0.05), color='red', linestyle='--')\n",
    "plt.axvline(x = np.log10(2), color='black', linestyle='--')\n",
    "plt.axvline(x = -np.log10(2), color='black', linestyle='--')\n",
    "plt.axvline(x=0, color='grey', linestyle='--')\n",
    "genesfinal = []\n",
    "\n",
    "for i,j in upregulated.iterrows():\n",
    "    genesfinal.append(j[0])\n",
    "    \n",
    "for i,j in downregulated.iterrows():\n",
    "    genesfinal.append(j[0])\n",
    "\n",
    "genesfinal \n",
    "\n",
    "\n",
    "\n",
    "len(genesfinal)\n",
    "genesfinal = [i for i in genesfinal if i in df3.index]\n",
    "df3.drop(axis=1,columns = genesfinal,inplace=True)\n",
    "fina = df3\n",
    "#fina.shape\n",
    "X = fina[df3.columns[13:]]\n",
    "X.head()\n",
    "y = df3['cat']\n",
    "y.head()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=41)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "logreg = LogisticRegression(solver='saga',random_state=41)\n",
    "rf = RandomForestClassifier(random_state=41,n_estimators=100,max_features=400)\n",
    "abc = AdaBoostClassifier(random_state=41)\n",
    "gbc = GradientBoostingClassifier(random_state=41,max_features=60)\n",
    "svc = SVC(random_state=41)\n",
    "\n",
    "models = [gnb,knn,logreg,rf,abc,svc]\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "d={}\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit_transform(X,y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=41)\n",
    "\n",
    "    \n",
    "    \n",
    "for i in models:\n",
    "    print(i,\": \",end = \" \")\n",
    "    i.fit(X_train,y_train)\n",
    "    preds = i.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy: \",accuracy_score(y_test,preds))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
